static int sctp_sendmsg(struct sock *sk, struct msghdr *msg, size_t msg_len) union sctp_addr to ; int err ; err = 0; if ( sctp_style ( sk , TCP ) && sctp_sstate ( sk , LISTENING ) )  err = sctp_msghdr_parse ( msg , & cmsgs ); static int sctp_msghdr_parse(const struct msghdr *msg, sctp_cmsgs_t *cmsgs) struct cmsghdr * cmsg ; struct msghdr * my_msg = ( struct msghdr * ) msg ; if ( ! CMSG_OK ( my_msg , cmsg ) )  return - EINVAL ; switch ( cmsg -> cmsg_type )  if ( cmsg -> cmsg_len != CMSG_LEN ( sizeof ( struct sctp_initmsg ) ) )  return - EINVAL ; cmsgs -> init = CMSG_DATA ( cmsg ); if ( cmsg -> cmsg_len != CMSG_LEN ( sizeof ( struct sctp_sndrcvinfo ) ) )  return - EINVAL ; cmsgs -> srinfo = CMSG_DATA ( cmsg ); if ( cmsgs -> srinfo -> sinfo_flags & ~ ( SCTP_UNORDERED | SCTP_ADDR_OVER | SCTP_SACK_IMMEDIATELY | SCTP_PR_SCTP_MASK | SCTP_ABORT | SCTP_EOF ) )  return - EINVAL ; if ( cmsg -> cmsg_len != CMSG_LEN ( sizeof ( struct sctp_sndinfo ) ) )  return - EINVAL ; cmsgs -> sinfo = CMSG_DATA ( cmsg ); if ( cmsgs -> sinfo -> snd_flags & ~ ( SCTP_UNORDERED | SCTP_ADDR_OVER | SCTP_SACK_IMMEDIATELY | SCTP_PR_SCTP_MASK | SCTP_ABORT | SCTP_EOF ) )  return - EINVAL ; return - EINVAL ; return 0 ; if ( err )  if ( ! sctp_style ( sk , UDP_HIGH_BANDWIDTH ) && msg -> msg_name )  int msg_namelen = msg -> msg_namelen ; err = sctp_verify_addr ( sk , ( union sctp_addr * ) msg -> msg_name , msg_namelen ); static inline int sctp_verify_addr(struct sock *sk, union sctp_addr int len) struct sctp_af * af ; af = sctp_sockaddr_af ( sctp_sk ( sk ) , addr , len ); static struct sctp_af *sctp_sockaddr_af(struct sctp_sock union sctp_addr *addr, int len) struct sctp_af * af ; if ( len < sizeof ( struct sockaddr ) )  return NULL ; if ( addr -> sa . sa_family == AF_INET6 && ipv6_addr_v4mapped ( & addr -> v6 . sin6_addr ) )  if ( ! opt -> pf -> af_supported ( AF_INET , opt ) )  return NULL ; if ( ! opt -> pf -> af_supported ( addr -> sa . sa_family , opt ) )  return NULL ; af = sctp_get_af_specific ( addr -> sa . sa_family ); if ( len < af -> sockaddr_len )  return NULL ; return af ; if ( ! af )  return - EINVAL ; if ( ! af -> addr_valid ( addr , sctp_sk ( sk ) , NULL ) )  return - EINVAL ; if ( ! sctp_sk ( sk ) -> pf -> send_verify ( sctp_sk ( sk ) , ( addr ) ) )  return - EINVAL ; return 0 ; if ( err )  if ( msg_namelen > sizeof ( to ) )  msg_namelen = sizeof ( to ); memcpy ( & to , msg -> msg_name , msg_namelen ); asoc = sctp_endpoint_lookup_assoc ( ep , & to , & transport ); if ( ! asoc && ( ( sctp_style ( sk , TCP ) && ( sctp_sstate ( sk , ESTABLISHED ) || sctp_sstate ( sk , CLOSING ) ) ) || sctp_endpoint_is_peeled_off ( ep , & to ) ) )  if ( asoc )  pr_debug ( "%s: just looked up association:%p\n" , __func__ , asoc ); if ( sctp_state ( asoc , CLOSED ) && sctp_style ( sk , TCP ) )  pr_debug ( "%s: shutting down association:%p\n" , __func__ , asoc ); sctp_primitive_SHUTDOWN ( net , asoc , NULL ); chunk = sctp_make_abort_user ( asoc , msg , msg_len ); if ( ! chunk )  pr_debug ( "%s: aborting association:%p\n" , __func__ , asoc ); sctp_primitive_ABORT ( net , asoc , chunk ); if ( ! asoc )  default_sinfo . sinfo_stream = asoc -> default_stream; default_sinfo . sinfo_flags = asoc -> default_flags; default_sinfo . sinfo_ppid = asoc -> default_ppid; default_sinfo . sinfo_context = asoc -> default_context; default_sinfo . sinfo_timetolive = asoc -> default_timetolive; default_sinfo . sinfo_assoc_id = sctp_assoc2id ( asoc ); sinfo = & default_sinfo; sinfo -> sinfo_timetolive = asoc -> default_timetolive; if ( asoc -> pmtu_pending )  sctp_assoc_pending_pmtu ( sk , asoc ); if ( sctp_sk ( sk ) -> disable_fragments && ( msg_len > asoc -> frag_point ) )  if ( sinfo -> sinfo_stream >= asoc -> c . sinit_num_ostreams )  if ( sctp_wspace ( asoc ) < msg_len )  static inline int sctp_wspace(struct sctp_association *asoc) if ( asoc -> ep -> sndbuf_policy )  amt = asoc -> sndbuf_used; amt = sk_wmem_alloc_get ( asoc -> base . sk ); if ( amt >= asoc -> base . sk -> sk_sndbuf )  if ( asoc -> base . sk -> sk_userlocks & SOCK_SNDBUF_LOCK )  amt = sk_stream_wspace ( asoc -> base . sk ); if ( amt < 0 )  amt = asoc -> base . sk -> sk_sndbuf - amt; return amt ; sctp_prsctp_prune ( asoc , sinfo , msg_len - sctp_wspace ( asoc ) ); static inline int sctp_wspace(struct sctp_association *asoc) if ( asoc -> ep -> sndbuf_policy )  amt = asoc -> sndbuf_used; amt = sk_wmem_alloc_get ( asoc -> base . sk ); if ( amt >= asoc -> base . sk -> sk_sndbuf )  if ( asoc -> base . sk -> sk_userlocks & SOCK_SNDBUF_LOCK )  amt = sk_stream_wspace ( asoc -> base . sk ); if ( amt < 0 )  amt = asoc -> base . sk -> sk_sndbuf - amt; return amt ; if ( ! sctp_wspace ( asoc ) )  static inline int sctp_wspace(struct sctp_association *asoc) if ( asoc -> ep -> sndbuf_policy )  amt = asoc -> sndbuf_used; amt = sk_wmem_alloc_get ( asoc -> base . sk ); if ( amt >= asoc -> base . sk -> sk_sndbuf )  if ( asoc -> base . sk -> sk_userlocks & SOCK_SNDBUF_LOCK )  amt = sk_stream_wspace ( asoc -> base . sk ); if ( amt < 0 )  amt = asoc -> base . sk -> sk_sndbuf - amt; return amt ; err = sctp_wait_for_sndbuf ( asoc , & timeo , msg_len ); static int sctp_wait_for_sndbuf(struct sctp_association *asoc, long size_t msg_len) struct sock * sk = asoc -> base . sk ; long current_timeo = * timeo_p ; pr_debug ( "%s: asoc:%p, timeo:%ld, msg_len:%zu\n" , __func__ , asoc , * timeo_p , msg_len ); sctp_association_hold ( asoc ); prepare_to_wait_exclusive ( & asoc -> wait , & wait , TASK_INTERRUPTIBLE ); if ( ! * timeo_p )  if ( sk -> sk_err || asoc -> state >= SCTP_STATE_SHUTDOWN_PENDING || asoc -> base . dead )  if ( msg_len <= sctp_wspace ( asoc ) )  static inline int sctp_wspace(struct sctp_association *asoc) if ( asoc -> ep -> sndbuf_policy )  amt = asoc -> sndbuf_used; amt = sk_wmem_alloc_get ( asoc -> base . sk ); if ( amt >= asoc -> base . sk -> sk_sndbuf )  if ( asoc -> base . sk -> sk_userlocks & SOCK_SNDBUF_LOCK )  amt = sk_stream_wspace ( asoc -> base . sk ); if ( amt < 0 )  amt = asoc -> base . sk -> sk_sndbuf - amt; return amt ; release_sock ( sk ); current_timeo = schedule_timeout ( current_timeo ); if ( sk != asoc -> base . sk )  lock_sock ( sk ); * timeo_p = current_timeo; finish_wait ( & asoc -> wait , & wait ); sctp_association_put ( asoc ); return err ; err = sock_intr_errno ( * timeo_p ); if ( err )  chunk_tp = sctp_assoc_lookup_paddr ( asoc , & to ); if ( ! chunk_tp )  if ( sctp_state ( asoc , CLOSED ) )  err = sctp_primitive_ASSOCIATE ( net , asoc , NULL ); if ( err < 0 )  datamsg = sctp_datamsg_from_user ( asoc , sinfo , & msg -> msg_iter ); if ( IS_ERR ( datamsg ) )  err = PTR_ERR ( datamsg ); list_for_each_entry ( chunk , & datamsg -> chunks , frag_list ) chunk -> transport = chunk_tp; err = sctp_primitive_SEND ( net , asoc , datamsg ); if ( err )  sctp_datamsg_free ( datamsg ); sctp_datamsg_put ( datamsg ); sctp_wait_for_connect ( asoc , & timeo ); static int sctp_wait_for_connect(struct sctp_association *asoc, long *timeo_p) struct sock * sk = asoc -> base . sk ; long current_timeo = * timeo_p ; pr_debug ( "%s: asoc:%p, timeo:%ld\n" , __func__ , asoc , * timeo_p ); sctp_association_hold ( asoc ); prepare_to_wait_exclusive ( & asoc -> wait , & wait , TASK_INTERRUPTIBLE ); if ( ! * timeo_p )  if ( sk -> sk_shutdown & RCV_SHUTDOWN )  if ( sk -> sk_err || asoc -> state >= SCTP_STATE_SHUTDOWN_PENDING || asoc -> base . dead )  if ( sctp_state ( asoc , ESTABLISHED ) )  release_sock ( sk ); current_timeo = schedule_timeout ( current_timeo ); lock_sock ( sk ); * timeo_p = current_timeo; finish_wait ( & asoc -> wait , & wait ); sctp_association_put ( asoc ); return err ; if ( asoc -> init_err_counter + 1 > asoc -> max_init_attempts )  err = sock_intr_errno ( * timeo_p ); sctp_association_free ( asoc ); return sctp_error ( sk , msg_flags , err ) ; static int sctp_error(struct sock *sk, int flags, int err) if ( err == - EPIPE )  err = sock_error ( sk ) ? : - EPIPE if ( err == - EPIPE && ! ( flags & MSG_NOSIGNAL ) )  return err ; 