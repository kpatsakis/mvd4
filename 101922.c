static int CVE_2009_4307_VULN_ext4_fill_flex_info(struct super_block *sb) struct ext4_sb_info * sbi = EXT4_SB ( sb ) ; ext4_group_t flex_group_count ; size_t size ; if ( ! sbi -> s_es -> s_log_groups_per_flex )  sbi -> s_log_groups_per_flex = sbi -> s_es -> s_log_groups_per_flex; groups_per_flex = 1 << sbi -> s_log_groups_per_flex; flex_group_count = ( ( sbi -> s_groups_count + groups_per_flex - 1 ) + ( ( le16_to_cpu ( sbi -> s_es -> s_reserved_gdt_blocks ) + 1 ) << EXT4_DESC_PER_BLOCK_BITS ( sb ) ) ) / groups_per_flex; size = flex_group_count * sizeof ( struct flex_groups ); sbi -> s_flex_groups = kzalloc ( size , GFP_KERNEL ); if ( sbi -> s_flex_groups == NULL )  sbi -> s_flex_groups = vmalloc ( size ); if ( sbi -> s_flex_groups )  memset ( sbi -> s_flex_groups , 0 , size ); if ( sbi -> s_flex_groups == NULL )  for (i = 0; i < sbi->s_groups_count; i++) flex_group = ext4_flex_group ( sbi , i ); atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_inodes , ext4_free_inodes_count ( sb , gdp ) ); atomic_set ( & sbi -> s_flex_groups [ flex_group ] . free_blocks , ext4_free_blks_count ( sb , gdp ) ); atomic_set ( & sbi -> s_flex_groups [ flex_group ] . used_dirs , ext4_used_dirs_count ( sb , gdp ) ); 