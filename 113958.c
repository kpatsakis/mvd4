static int sctp_setsockopt(struct sock *sk, int level, int char __user *optval, unsigned int optlen) if ( level != SOL_SCTP )  switch ( optname )  retval = sctp_setsockopt_bindx ( sk , ( struct sockaddr __user * ) optval , optlen , SCTP_BINDX_ADD_ADDR ); static int sctp_setsockopt_bindx(struct sock struct sockaddr __user int addrs_size, int op) struct sockaddr * kaddrs ; int err ; int addrcnt = 0 ; int walk_size = 0 ; struct sockaddr * sa_addr ; void * addr_buf ; struct sctp_af * af ; if ( unlikely ( addrs_size <= 0 ) )  if ( unlikely ( ! access_ok ( VERIFY_READ , addrs , addrs_size ) ) )  kaddrs = kmalloc ( addrs_size , GFP_USER | __GFP_NOWARN ); if ( unlikely ( ! kaddrs ) )  if ( __copy_from_user ( kaddrs , addrs , addrs_size ) )  addr_buf = kaddrs; while ( walk_size < addrs_size )  if ( walk_size + sizeof ( sa_family_t ) > addrs_size )  sa_addr = addr_buf; af = sctp_get_af_specific ( sa_addr -> sa_family ); if ( ! af || ( walk_size + af -> sockaddr_len ) > addrs_size )  addrcnt ++; addr_buf += af -> sockaddr_len; walk_size += af -> sockaddr_len; switch ( op )  err = sctp_bindx_add ( sk , kaddrs , addrcnt ); static int sctp_bindx_add(struct sock *sk, struct sockaddr *addrs, int addrcnt) int cnt ; int retval = 0 ; void * addr_buf ; struct sockaddr * sa_addr ; struct sctp_af * af ; addr_buf = addrs; for (cnt = 0; cnt < addrcnt; cnt++) sa_addr = addr_buf; af = sctp_get_af_specific ( sa_addr -> sa_family ); if ( ! af )  retval = - EINVAL; retval = sctp_do_bind ( sk , ( union sctp_addr * ) sa_addr , af -> sockaddr_len ); static int sctp_do_bind(struct sock *sk, union sctp_addr *addr, int len) struct net * net = sock_net ( sk ) ; struct sctp_sock * sp = sctp_sk ( sk ) ; struct sctp_endpoint * ep = sp -> ep ; struct sctp_bind_addr * bp = & ep -> base . bind_addr ; struct sctp_af * af ; unsigned short snum ; af = sctp_sockaddr_af ( sp , addr , len ); static struct sctp_af *sctp_sockaddr_af(struct sctp_sock union sctp_addr *addr, int len) struct sctp_af * af ; if ( len < sizeof ( struct sockaddr ) )  return NULL ; if ( addr -> sa . sa_family == AF_INET6 && ipv6_addr_v4mapped ( & addr -> v6 . sin6_addr ) )  if ( ! opt -> pf -> af_supported ( AF_INET , opt ) )  return NULL ; if ( ! opt -> pf -> af_supported ( addr -> sa . sa_family , opt ) )  return NULL ; af = sctp_get_af_specific ( addr -> sa . sa_family ); if ( len < af -> sockaddr_len )  return NULL ; return af ; if ( ! af )  return - EINVAL ; snum = ntohs ( addr -> v4 . sin_port ); if ( ! sp -> pf -> bind_verify ( sp , addr ) )  return - EADDRNOTAVAIL ; if ( bp -> port )  if ( ! snum )  snum = bp -> port; if ( snum != bp -> port )  return - EINVAL ; if ( snum && snum < PROT_SOCK && ! ns_capable ( net -> user_ns , CAP_NET_BIND_SERVICE ) )  return - EACCES ; if ( sctp_bind_addr_match ( bp , addr , sp ) )  return - EINVAL ; addr -> v4 . sin_port = htons ( snum ); if ( ret = sctp_get_port_local ( sk , addr ) )  static long sctp_get_port_local(struct sock *sk, union sctp_addr *addr) struct sctp_bind_hashbucket * head ; struct sctp_bind_bucket * pp ; unsigned short snum ; int ret ; snum = ntohs ( addr -> v4 . sin_port ); if ( snum == 0 )  int low , high , remaining , index ; unsigned int rover ; struct net * net = sock_net ( sk ) ; remaining = ( high - low ) + 1; rover = prandom_u32 ( ) % remaining + low; rover ++; if ( ( rover < low ) || ( rover > high ) )  rover = low; if ( inet_is_local_reserved_port ( net , rover ) )  index = sctp_phashfn ( sock_net ( sk ) , rover ); head = & sctp_port_hashtable [ index ]; if ( ( pp -> port == rover ) && net_eq ( sock_net ( sk ) , pp -> net ) )  while ( -- remaining > 0 )  ret = 1; if ( remaining <= 0 )  snum = rover; head = & sctp_port_hashtable [ sctp_phashfn ( sock_net ( sk ) , snum ) ]; if ( ( pp -> port == snum ) && net_eq ( pp -> net , sock_net ( sk ) ) )  pp = NULL; if ( ! hlist_empty ( & pp -> owner ) )  struct sock * sk2 ; if ( pp -> fastreuse && sk -> sk_reuse && sk -> sk_state != SCTP_SS_LISTENING )  struct sctp_endpoint * ep2 ; ep2 = sctp_sk ( sk2 ) -> ep; if ( sctp_bind_addr_conflict ( & ep2 -> base . bind_addr , addr , sctp_sk ( sk2 ) , sctp_sk ( sk ) ) )  ret = ( long ) sk2; ret = 1; if ( ! pp && ! ( pp = sctp_bucket_create ( head , sock_net ( sk ) , snum ) ) )  static struct sctp_bind_bucket struct sctp_bind_hashbucket *head, struct net *net, unsigned short snum) struct sctp_bind_bucket * pp ; pp = kmem_cache_alloc ( sctp_bucket_cachep , GFP_ATOMIC ); if ( pp )  pp -> port = snum; pp -> fastreuse = 0; pp -> net = net; return pp ; ret = 0; return ret ; return - EADDRINUSE ; if ( ! bp -> port )  bp -> port = inet_sk ( sk ) -> inet_num; ret = sctp_add_bind_addr ( bp , addr , af -> sockaddr_len , SCTP_ADDR_SRC , GFP_ATOMIC ); return ret ; addr_buf += af -> sockaddr_len; if ( retval < 0 )  return retval ; return retval ; if ( err )  err = sctp_send_asconf_add_ip ( sk , kaddrs , addrcnt ); static int sctp_send_asconf_add_ip(struct struct int 			addrcnt) struct net * net = sock_net ( sk ) ; struct sctp_association * asoc ; struct sctp_bind_addr * bp ; struct sctp_chunk * chunk ; struct sctp_sockaddr_entry * laddr ; union sctp_addr * addr ; union sctp_addr saveaddr ; void * addr_buf ; struct sctp_af * af ; struct list_head * p ; int i ; if ( ! net -> sctp . addip_enable )  addr_buf = addrs; for (i = 0; i < addrcnt; i++) addr = addr_buf; af = sctp_get_af_specific ( addr -> v4 . sin_family ); if ( ! af )  if ( sctp_assoc_lookup_laddr ( asoc , addr ) )  addr_buf += af -> sockaddr_len; bp = & asoc -> base . bind_addr; p = bp -> address_list . next; laddr = list_entry ( p , struct sctp_sockaddr_entry , list ) chunk = sctp_make_asconf_update_ip ( asoc , & laddr -> a , addrs , addrcnt , SCTP_PARAM_ADD_IP ); if ( ! chunk )  addr_buf = addrs; for (i = 0; i < addrcnt; i++) addr = addr_buf; af = sctp_get_af_specific ( addr -> v4 . sin_family ); memcpy ( & saveaddr , addr , af -> sockaddr_len ); retval = sctp_add_bind_addr ( bp , & saveaddr , sizeof ( saveaddr ) , SCTP_ADDR_NEW , GFP_ATOMIC ); addr_buf += af -> sockaddr_len; return retval ; 