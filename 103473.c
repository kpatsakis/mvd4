static CVE_2011_1495_VULN__ctl_do_mpt_command(struct MPT2SAS_ADAPTER struct mpt2_ioctl_command karg, void __user *mf, enum block_state state) u32 ioc_state ; u16 smid ; u16 wait_state_count ; if ( state == NON_BLOCKING && ! mutex_trylock ( & ioc -> ctl_cmds . mutex ) )  if ( mutex_lock_interruptible ( & ioc -> ctl_cmds . mutex ) )  if ( ioc -> ctl_cmds . status != MPT2_CMD_NOT_USED )  wait_state_count = 0; ioc_state = mpt2sas_base_get_iocstate ( ioc , 1 ); while ( ioc_state != MPI2_IOC_STATE_OPERATIONAL )  if ( wait_state_count ++ == 10 )  ioc_state = mpt2sas_base_get_iocstate ( ioc , 1 ); mpi_request = kzalloc ( ioc -> request_sz , GFP_KERNEL ); if ( ! mpi_request )  if ( copy_from_user ( mpi_request , mf , karg . data_sge_offset * 4 ) )  if ( mpi_request -> Function == MPI2_FUNCTION_SCSI_TASK_MGMT )  smid = mpt2sas_base_get_smid_hpr ( ioc , ioc -> ctl_cb_idx ); if ( ! smid )  smid = mpt2sas_base_get_smid_scsiio ( ioc , ioc -> ctl_cb_idx , NULL ); if ( ! smid )  ioc -> ctl_cmds . status = MPT2_CMD_PENDING; memset ( ioc -> ctl_cmds . reply , 0 , ioc -> reply_sz ); ioc -> ctl_cmds . smid = smid; data_out_sz = karg . data_out_size; data_in_sz = karg . data_in_size; if ( mpi_request -> Function == MPI2_FUNCTION_SCSI_IO_REQUEST || mpi_request -> Function == MPI2_FUNCTION_RAID_SCSI_IO_PASSTHROUGH )  if ( ! le16_to_cpu ( mpi_request -> FunctionDependent1 ) || le16_to_cpu ( mpi_request -> FunctionDependent1 ) > ioc -> facts . MaxDevHandle )  if ( data_out_sz )  data_out = pci_alloc_consistent ( ioc -> pdev , data_out_sz , & data_out_dma ); if ( ! data_out )  if ( copy_from_user ( data_out , karg . data_out_buf_ptr , data_out_sz ) )  if ( data_in_sz )  data_in = pci_alloc_consistent ( ioc -> pdev , data_in_sz , & data_in_dma ); if ( ! data_in )  switch ( mpi_request -> Function )  memset ( ioc -> ctl_cmds . sense , 0 , SCSI_SENSE_BUFFERSIZE ); 