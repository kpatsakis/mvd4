static sg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg) void __user * p = ( void __user * ) arg ; int __user * ip = p ; int result , val , read_only ; Sg_device * sdp ; Sg_fd * sfp ; Sg_request * srp ; if ( ( ! ( sfp = ( Sg_fd * ) filp -> private_data ) ) || ( ! ( sdp = sfp -> parentdp ) ) )  read_only = ( O_RDWR != ( filp -> f_flags & O_ACCMODE ) ); switch ( cmd_in )  if ( atomic_read ( & sdp -> detaching ) )  if ( ! scsi_block_when_processing_errors ( sdp -> device ) )  if ( ! access_ok ( VERIFY_WRITE , p , SZ_SG_IO_HDR ) )  result = sg_new_write ( sfp , filp , p , SZ_SG_IO_HDR , 1 , read_only , 1 , & srp ); static sg_new_write(Sg_fd *sfp, struct file *file, const char __user size_t count, int blocking, int read_only, int Sg_request **o_srp) int k ; Sg_request * srp ; sg_io_hdr_t * hp ; unsigned char cmnd [ SG_MAX_CDB_SIZE ] ; int timeout ; unsigned long ul_timeout ; if ( count < SZ_SG_IO_HDR )  return - EINVAL ; if ( ! access_ok ( VERIFY_READ , buf , count ) )  return - EFAULT ; sfp -> cmd_q = 1; if ( ! ( srp = sg_add_request ( sfp ) ) )  static Sg_request sg_add_request(Sg_fd * sfp) int k ; Sg_request * resp ; Sg_request * rp = sfp -> req_arr ; resp = sfp -> headrp; if ( ! resp )  memset ( rp , 0 , sizeof ( Sg_request ) ); rp -> parentfp = sfp; resp = rp; if ( 0 == sfp -> cmd_q )  resp = NULL; if ( k < SG_MAX_QUEUE )  memset ( rp , 0 , sizeof ( Sg_request ) ); rp -> parentfp = sfp; while ( resp -> nextrp )  resp = resp -> nextrp; resp -> nextrp = rp; resp = rp; resp = NULL; if ( resp )  resp -> nextrp = NULL; resp -> header . duration = jiffies_to_msecs ( jiffies ); return resp ; return - EDOM ; srp -> sg_io_owned = sg_io_owned; hp = & srp -> header; if ( __copy_from_user ( hp , buf , SZ_SG_IO_HDR ) )  return - EFAULT ; if ( hp -> interface_id != 'S' )  return - ENOSYS ; if ( hp -> flags & SG_FLAG_MMAP_IO )  if ( hp -> dxfer_len > sfp -> reserve . bufflen )  return - ENOMEM ; if ( hp -> flags & SG_FLAG_DIRECT_IO )  return - EINVAL ; if ( sg_res_in_use ( sfp ) )  static sg_res_in_use(Sg_fd * sfp) const Sg_request * srp ; for (srp = sfp->headrp; srp; srp = srp->nextrp) if ( srp -> res_used )  return srp ? 1 : 0 ; return - EBUSY ; ul_timeout = msecs_to_jiffies ( srp -> header . timeout ); timeout = ( ul_timeout < INT_MAX ) ? ul_timeout : INT_MAX; if ( ( ! hp -> cmdp ) || ( hp -> cmd_len < 6 ) || ( hp -> cmd_len > sizeof ( cmnd ) ) )  return - EMSGSIZE ; if ( ! access_ok ( VERIFY_READ , hp -> cmdp , hp -> cmd_len ) )  return - EFAULT ; if ( __copy_from_user ( cmnd , hp -> cmdp , hp -> cmd_len ) )  return - EFAULT ; if ( read_only && sg_allow_access ( file , cmnd ) )  static int sg_allow_access(struct file *filp, unsigned char *cmd) struct sg_fd * sfp = filp -> private_data ; if ( sfp -> parentdp -> device -> type == TYPE_SCANNER )  return 0 ; return blk_verify_command ( cmd , filp -> f_mode & FMODE_WRITE ) ; return - EPERM ; k = sg_common_write ( sfp , srp , cmnd , timeout , blocking ); if ( k < 0 )  return k ; return count ; if ( result < 0 )  result = wait_event_interruptible ( sfp -> read_wait , ( srp_done ( sfp , srp ) || atomic_read ( & sdp -> detaching ) ) ); static int srp_done(Sg_fd *sfp, Sg_request *srp) int ret ; ret = srp -> done; return ret ; result = get_user ( val , ip ); if ( result )  if ( val < 0 )  if ( val >= MULDIV ( INT_MAX , USER_HZ , HZ ) )  val = MULDIV ( INT_MAX , USER_HZ , HZ ); sfp -> timeout_user = val; sfp -> timeout = MULDIV ( val , HZ , USER_HZ ); result = get_user ( val , ip ); if ( result )  if ( val )  sfp -> low_dma = 1; if ( ( 0 == sfp -> low_dma ) && ( 0 == sg_res_in_use ( sfp ) ) )  static sg_res_in_use(Sg_fd * sfp) const Sg_request * srp ; if ( srp -> res_used )  return srp ? 1 : 0 ; val = ( int ) sfp -> reserve . bufflen; if ( atomic_read ( & sdp -> detaching ) )  sfp -> low_dma = sdp -> device -> host -> unchecked_isa_dma; result = get_user ( val , ip ); if ( result )  sfp -> force_packid = val ? 1 : 0; result = get_user ( val , ip ); if ( result )  if ( val < 0 )  val = min_t ( int , val , max_sectors_bytes ( sdp -> device -> request_queue ) ); static int max_sectors_bytes(struct request_queue *q) unsigned int max_sectors = queue_max_sectors ( q ) ; max_sectors = min_t ( unsigned int , max_sectors , INT_MAX >> 9 ) return max_sectors << 9 ; if ( val != sfp -> reserve . bufflen )  if ( sg_res_in_use ( sfp ) || sfp -> mmap_called )  static sg_res_in_use(Sg_fd * sfp) const Sg_request * srp ; if ( srp -> res_used )  return srp ? 1 : 0 ; sg_remove_scat ( sfp , & sfp -> reserve ); static sg_remove_scat(Sg_fd * sfp, Sg_scatter_hold * schp) memset ( schp , 0 , sizeof ( * schp ) ); 